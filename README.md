# Denoising-Of-Image-Using-GAN
Image denoising using Generative Adversarial Networks (GANs) is a technique for removing noise from digital images by training a neural network to generate clean images from noisy ones GANs are deep learning models
that consist of two neural networks, a generator, and a discriminator, that work together to learn the underlying distribution of a given dataset. By using a GAN-based approach, image denoising can be formulated as an unsupervised learning problem, where the generator is trained to produce a clean image from a noisy input, while the discriminator is trained to differentiate between real clean images and generated clean images. The GAN-based approach to image denoising has several advantages over traditional methods, such as the ability to produce realistic and visually pleasing images, and the potential for generalization to unseen noise patterns. However, training GANs can be challenging due to the instability of the training process and the need for large amounts of data. Recent advancements in GAN architectures and training techniques have addressed some of these challenges and have led to improved image denoising performance. Overall, GAN-based image denoising is a promising research direction that has the potential to improve the quality of noisy images in a variety of applications, including medical imaging, surveillance, and photography.

![image](https://github.com/Ujjwalh/Denoising-Of-Image-Using-GAN/assets/69312276/aa589d40-0b7b-4493-a3a3-3d2aeef79290)


We used Google Colab with GPU runtime. It is a popular choice for deep learning projects because it allows you to access powerful hardware resources for free. The GPU runtime on Google Colab provides us with a high- performance computing environment that can significantly reduce the time it takes to train.

Dataset Creation
To ensure that the model is trained properly, it is important to have a diverse and sufficiently large dataset. Therefore, we created our own dataset by collecting random pictures of leaves, which resulted in a dataset containing 1100 images for training and 300 images for testing. To work with a fixed dimension, we cropped each image to a size of (256, 256, 3). To make the network more robust, the cropped area was chosen randomly. During the dataset loading and creation of the test and train sets, we only accepted images that had 3 channels and were larger than 256x256 in size. This was done to ensure that the dataset contained high-quality images that could be used to train a powerful mode.
