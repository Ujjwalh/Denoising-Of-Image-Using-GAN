# -*- coding: utf-8 -*-
"""training .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RIzkAgiarwio6s1a0weAFskHfKbDyNd7
"""

import numpy as np
import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from keras.models import Model
from keras.optimizers import Adam
from PIL import UnidentifiedImageError
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Conv2DTranspose
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Input, Dense, BatchNormalization, Activation, Reshape, Flatten, Dropout, Concatenate
from keras.layers import LeakyReLU, PReLU
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.models import Model
import tensorflow as tf
from tensorflow.keras import regularizers

def load_images(directory, label):
    images = []
    for filename in os.listdir(directory):
        if filename.endswith(".jpg") or filename.endswith(".png"):
            img_path = os.path.join(directory, filename)
            try:
                img = load_img(img_path, target_size=(256, 256))
                img_array = img_to_array(img.convert('RGB')).astype('float32')
                images.append((img_array, label))
            except UnidentifiedImageError:
                print(f'Skipping image {filename}: cannot identify image file')
    return np.array(images , dtype=object)

# Define the generator model
def create_denoiser_model(input_shape):
    # Define the input layer
    input_layer = Input(shape=input_shape)

    # Encoder
    enc_layer1 = Conv2D(64, kernel_size=3, strides=1, padding='same')(input_layer)
    enc_layer1 = BatchNormalization()(enc_layer1)
    enc_layer1 = LeakyReLU(alpha=0.2)(enc_layer1)

    enc_layer2 = Conv2D(128, kernel_size=3, strides=2, padding='same')(enc_layer1)
    enc_layer2 = BatchNormalization()(enc_layer2)
    enc_layer2 = LeakyReLU(alpha=0.2)(enc_layer2)

    enc_layer3 = Conv2D(256, kernel_size=3, strides=2, padding='same')(enc_layer2)
    enc_layer3 = BatchNormalization()(enc_layer3)
    enc_layer3 = LeakyReLU(alpha=0.2)(enc_layer3)

    enc_layer4 = Conv2D(512, kernel_size=3, strides=2, padding='same')(enc_layer3)
    enc_layer4 = BatchNormalization()(enc_layer4)
    enc_layer4 = LeakyReLU(alpha=0.2)(enc_layer4)

    # Decoder
    dec_layer1 = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same')(enc_layer4)
    dec_layer1 = BatchNormalization()(dec_layer1)
    dec_layer1 = LeakyReLU(alpha=0.2)(dec_layer1)

    dec_layer2 = Concatenate()([dec_layer1, enc_layer3])
    dec_layer2 = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(dec_layer2)
    dec_layer2 = BatchNormalization()(dec_layer2)
    dec_layer2 = LeakyReLU(alpha=0.2)(dec_layer2)

    dec_layer3 = Concatenate()([dec_layer2, enc_layer2])
    dec_layer3 = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(dec_layer3)
    dec_layer3 = BatchNormalization()(dec_layer3)
    dec_layer3 = LeakyReLU(alpha=0.2)(dec_layer3)

    dec_layer4 = Concatenate()([dec_layer3, enc_layer1])
    dec_layer4 = Conv2DTranspose(3, kernel_size=3, strides=1, padding='same')(dec_layer4)
    dec_layer4 = Activation('sigmoid')(dec_layer4)

    # Define the output layer
    output_layer = dec_layer4

    # Define the generator model
    model = Model(inputs=[input_layer], outputs=[output_layer], name='generator')
    model.compile(loss='mean_squared_error',
              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),
              metrics=['accuracy'])
    return model

# Load the pre-trained generator model
input_shape= (256,256,3)
generator = create_denoiser_model(input_shape)
generator.load_weights('/content/denoiser_model2.h5')

def create_discriminator_model(input_shape):
    input_layer = Input(shape=input_shape)

    # Convolutional layers
    conv_layer1 = Conv2D(64, kernel_size=3, strides=2, padding='same')(input_layer)
    conv_layer1 = LeakyReLU(alpha=0.2)(conv_layer1)

    conv_layer2 = Conv2D(128, kernel_size=3, strides=2, padding='same')(conv_layer1)
    conv_layer2 = BatchNormalization()(conv_layer2)
    conv_layer2 = LeakyReLU(alpha=0.2)(conv_layer2)

    conv_layer3 = Conv2D(256, kernel_size=3, strides=2, padding='same')(conv_layer2)
    conv_layer3 = BatchNormalization()(conv_layer3)
    conv_layer3 = LeakyReLU(alpha=0.2)(conv_layer3)

    conv_layer4 = Conv2D(512, kernel_size=3, strides=2, padding='same')(conv_layer3)
    conv_layer4 = BatchNormalization()(conv_layer4)
    conv_layer4 = LeakyReLU(alpha=0.2)(conv_layer4)

    conv_layer5 = Conv2D(512, kernel_size=3, strides=2, padding='same')(conv_layer4)
    conv_layer5 = BatchNormalization()(conv_layer5)
    conv_layer5 = LeakyReLU(alpha=0.2)(conv_layer5)

    conv_layer6 = Conv2D(512, kernel_size=3, strides=2, padding='same')(conv_layer5)
    conv_layer6 = BatchNormalization()(conv_layer6)
    conv_layer6 = LeakyReLU(alpha=0.2)(conv_layer6)

    # Flatten the output from the convolutional layers
    flatten_layer = Flatten()(conv_layer6)

    # Dense layers
    dense_layer1 = Dense(1024)(flatten_layer)
    dense_layer1 = LeakyReLU(alpha=0.2)(dense_layer1)

    dense_layer2 = Dense(512)(dense_layer1)
    dense_layer2 = LeakyReLU(alpha=0.2)(dense_layer2)

    dense_layer3 = Dense(256)(dense_layer2)
    dense_layer3 = LeakyReLU(alpha=0.2)(dense_layer3)

    # Output layer
    output_layer = Dense(1, activation='sigmoid')(dense_layer3)

    model = Model(inputs=[input_layer], outputs=[output_layer], name='discriminator')
    model.compile(loss='binary_crossentropy',
                  optimizer=Adam(lr=0.0002, beta_1=0.5),
                  metrics=['accuracy'])

    return model



# Load the pre-trained discriminator model
input_shape= (256,256,3)
discriminator = create_discriminator_model(input_shape)
discriminator.load_weights('/content/discriminator_model.h5')

# Function to generate and save sample images
def generate_and_save_images(model, epoch, test_input):
    # Generate images from the model
    generated_images = model.predict(test_input)

    # Rescale pixel values from [-1, 1] to [0, 1]
    generated_images = 0.5 * generated_images + 0.5

    # Create a figure to display the images
    fig, axs = plt.subplots(5, 5, figsize=(10, 10))
    count = 0
    for i in range(5):
        for j in range(5):
            # Display the generated image
            axs[i, j].imshow(generated_images[count])
            axs[i, j].axis('off')
            count += 1

    # Save the figure
    plt.savefig(f'generated_images_epoch_{epoch}.png')
    plt.close()

# Freeze the discriminator weights during generator training
discriminator.trainable = False

# Define the combined model
img_input = Input(shape=input_shape)
img = generator(img_input)
valid = discriminator(img)
combined = Model(img_input, valid)
combined.compile(loss='mse', optimizer=Adam(lr=0.0001, beta_1=0.5))

# Load the dataset
dataset = load_images('/content/data/train data', 1)
dataset = np.concatenate((dataset, load_images('/content/data/train gnd', 0)))

# Train the GAN
epochs = 50
batch_size = 32
steps_per_epoch = int(dataset.shape[0] / batch_size)
for epoch in range(epochs):
    # Train the discriminator
    idx = np.random.randint(0, dataset.shape[0], batch_size)
    real_imgs, labels = zip(*dataset[idx])
    real_imgs = np.array(real_imgs)
    labels = np.array(labels)
    fake_imgs = generator.predict(np.random.normal(0, 1, (batch_size,) + input_shape))
    d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((batch_size, 1)))
    d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((batch_size, 1)))
    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

    # Train the generator
    idx = np.random.randint(0, dataset.shape[0], batch_size)
    real_imgs, labels = zip(*dataset[idx])
    real_imgs = np.array(real_imgs)
    labels = np.array(labels)
    g_loss = combined.train_on_batch(real_imgs, np.ones((batch_size, 1)))

    # Print the progress
    print(f'Epoch {epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss}]')

    combined.save_weights('/content/combined_model_weights.h5')